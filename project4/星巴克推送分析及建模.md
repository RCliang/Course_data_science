# 简介
星巴克提供了一批数据包含每个推送的相关信息，人们对推送的反应接收，阅读，成交三种，人们的基本信息三个数据集，我们需要通过这些数据去分析哪些推送的效果比较不错，然后针对人群对推送的行为数据，人群的基本信息和推送的基本信息搭建一个机器学习模型来预测什么样的人群在什么样的推送下是否会进行购买。

# 目标
建立一个预测模型去预测人是否会使用推送进行购买

# 数据集
一共有三个数据文件：

* portfolio.json – 包括推送的 id 和每个推送的元数据（持续时间、种类等等）
* profile.json – 每个顾客的人口统计数据
* transcript.json – 交易、收到的推送、查看的推送和完成的推送的记录

以下是文件中每个变量的类型和解释 ：

**portfolio.json**
* id (string) – 推送的id
* offer_type (string) – 推送的种类，例如 BOGO、打折（discount）、信息（informational）
* difficulty (int) – 满足推送的要求所需的最少花费
* reward (int) – 满足推送的要求后给与的优惠
* duration (int) – 推送持续的时间，单位是天
* channels (字符串列表)

**profile.json**
* age (int) – 顾客的年龄 
* became_member_on (int) – 该顾客第一次注册app的时间
* gender (str) – 顾客的性别（注意除了表示男性的 M 和表示女性的 F 之外，还有表示其他的 O）
* id (str) – 顾客id
* income (float) – 顾客的收入

**transcript.json**
* event (str) – 记录的描述（比如交易记录、推送已收到、推送已阅）
* person (str) – 顾客id
* time (int) – 单位是小时，测试开始时计时。该数据从时间点 t=0 开始
* value - (dict of strings) – 推送的id 或者交易的数额

# 方案
* 首先，通过数据预处理profile的信息，将客户行为拆分出来
* 通过漏斗分析，评价不同推送的效果如何
* 数据处理：聚合客户的行为数据，做出行为特征，并合并人群基本信息，推送基本信息，建立训练和测试样本
* 训练模型
* 对模型进行效果评价，并提出可进行改进的建议

# 简单数据统计及各offer转化
* 通过拆分出的客户行为：收到，阅读，完成offer建立一个三级的**漏斗分析**，来分析哪个推送的转化率比较高。
拆分transcript这个数据集后，发现：\
    收到offer人数: **16994** \
    查看offer人数: **16834** \
    进行交易人数: **16578** \
    完成offer人数: **12774** \
整个数据集并不大，一共也就10各推送，因此很快就通过pandas很快得出以下表格：\
![avatar](./漏斗.png)\
可以看到index为9的推送是表现最好的，view_pct阅读率高达96.4%为最高，complete_pct转化率为70.0%也为最高。同时也可以看到其中有两个推送是没有转化率的，查看portfolio,可以发现因为它们只是推送提醒并没有优惠券或买一送一。而index为9的推送之所以能取得这样的效果也是因为它的**渠道最多，难度最大，持续时间最长**：\
![avatar](./offer.png)\

# 建模数据探索
- 根据三个不同的数据集，可以将待选因子总结为以下三个方面：\
  - offer性质相关的因子: difficulty, duration, channels, offer_type, reward
  - 客户基本信息相关的因子: age, 成为会员的时间， sex, income
  - 客户历史行为：平均交易金额，查看offer距离收到offer的平均时长view_gap，查看offer的次数view_times

* 客户平均交易金额
大多数的交易金额都小于10元，因此去除大于10元的情况下，可以下看到下面的histgram：\
如果使用逻辑回归的方式建模的话，肯定是要将特别大异常值进行去除或者进行分箱增加模型鲁棒性。\
![avatar](./平均交易金额.png)\
同理的还有，客户查看offer的次数view_times \
![avatar](./查看次数.png)\

* 客户基本信息分析
 * 客户的年龄分布如下：\
![avatar](./年龄.png)\
可以发现客户的年龄平均在50至60岁，但明显有些异常数据，高于100岁的应该属于异常值，需要加以去除或者分箱。
 * 客户的收入分布如下：\
![avatar](./收入.png)\
可以看到客户收入属于右偏的正太分布，没有什么太大问题。
 * 客户的年龄分布如下：\

    |性别|数量|
    |-|-|-|
    |M|75|
    |F|79|
    |O|92|

* 各offer的基本信息分析
 * 每个offer都有difficulty,duration,channels,offer_type,reward的信息，其中difficulty,duration和reward均为连续型变量，offer_type,channels是离散型变量，如果使用线性的模型时，需要做独热编码处理。

* 缺失值处理
  将数据按照person_id和offer_id merge之后我们得到了建模所需要的数据，接下来将做缺失值处理：
  其中出现缺失的有如下字段：\

    |字段|缺失率|
    |-|-|-|
    |view_gap|6.2%|
    |amount_mean|24.7%|
    |view_times|6.2%|
    |income|12.7%|

其中，view_gap, amount_mean, view_times都是我们自己加工的字段，缺失代表了客户并没有查看推送或者发生交易，因此有实际意义将其填充为0。而income则为原始数据，代表没有提供到真实的数据，因此我们将其使用平均值填充。最后加工而成的变量如下：\
 * amount_mean: 平均交易金额
 * difficulty：offer推送难度
 * duration：持续时长
 * reward：优惠力度
 * became_member_on: 成为会员日
 * view_times: 查看推送次数
 * offer_type: offer种类
 * income：收入
 * age：年龄
 * view_gap：查看offer距离收到offer的平均时长
 * gender：性别
 * is_social：是否社交推送
 * is_mobile：是否通过手机推送
 * is_web：是否网络端推送
 * is_email：是否邮件推送

# 特征重要性分析
因为打算使用gbdt这种回归树的集成模型，因此直接使用其feature_importances进行筛选，结果如下：\
![avatar](./特征重要性.png)\
可以看到amount_mean,difficulty,duration,reward都是比较重要的因子，而通过何种方式进行推送和性别确是比较差的特征。因此将这几个因子删除出数据集，然后使用train_test_split进行训练集和测试集的切分：
```
X_new=df_mid.drop(['complete_tag','is_email','is_web','gender','is_mobile'],axis=1)
tag_col=df_mid['complete_tag']
X_train, X_test, y_train, y_test = train_test_split(X_new, tag_col, test_size=0.3,random_state=0)
```
使用了gbdt先跑了一把模型:
```
param_test = {
        'learning_rate': [0.1, 0.05],
        'max_depth': [3,5],
        'n_estimators': range(50, 200, 50),
        'min_samples_split': [5, 20, 50, 70, 100]
        }
GBC = GradientBoostingClassifier()
gsearch = GridSearchCV(GBC, param_grid=param_test, scoring="roc_auc", cv=5)
gsearch.fit(X_train, y_train)
y_pred=gsearch.predict(X_test)
```

使用了sklearn的GridSearch模块，对参数进行调参，评判标准采用了roc_auc,用5折交叉检验。
最后使用如下代码得到了混淆矩阵，准确率和最佳参数，得到的结果如下：

```
def display_results(cv, y_test, y_pred):
    labels = np.unique(y_pred)
    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)
    accuracy = (y_pred == y_test).mean()
    auc_score = f1_score(y_test, y_pred)
    
    print("Labels:", labels)
    print("Confusion Matrix:\n", confusion_mat)
    print("Accuracy:", accuracy)
    print("\nBest Parameters:", cv.best_params_)
    print("f1_score", auc_score)
display_results(gsearch, y_test, y_pred)
```

 * 混淆矩阵：\

    |8490|1786|
    |-|-|-|
    |846|7865|

 * 准确率： 86.1%

 * 最佳参数： {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 50, 'n_estimators': 100} \
 * f1分数： 0.8566604945

# 结论
目前经过一些简单的数据分析，和比较粗糙的建模方法得到了一个通过客户基本信息，客户历史行为特征和offer基本信息的数据去预测客户是否会对offer响应并完成offer的模型。

# 可改进方向
目前针对户行为特征这块的数据还可以进一步的拆分，有些客户并不是因为offer而进行了交易，而纯粹是习惯了，甚至是完成offer后才查看到offer，因此需要将数据再进行一次拆分，针对那部分不是因为惯性的客户进行建模。



